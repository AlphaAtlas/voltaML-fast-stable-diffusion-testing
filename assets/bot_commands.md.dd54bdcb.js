import{_ as e,c as a,o,a as d}from"./app.25052814.js";const f=JSON.parse('{"title":"Commands","description":"","frontmatter":{},"headers":[{"level":2,"title":"Avaliable","slug":"avaliable","link":"#avaliable","children":[]},{"level":2,"title":"Clean-memory","slug":"clean-memory","link":"#clean-memory","children":[]},{"level":2,"title":"Dream","slug":"dream","link":"#dream","children":[]},{"level":2,"title":"GPUS","slug":"gpus","link":"#gpus","children":[]},{"level":2,"title":"Load","slug":"load","link":"#load","children":[]},{"level":2,"title":"Loaded","slug":"loaded","link":"#loaded","children":[]},{"level":2,"title":"Reset-queue","slug":"reset-queue","link":"#reset-queue","children":[]},{"level":2,"title":"Sync","slug":"sync","link":"#sync","children":[]},{"level":2,"title":"Unload","slug":"unload","link":"#unload","children":[]}],"relativePath":"bot/commands.md","lastUpdated":1680009439000}'),l={name:"bot/commands.md"},t=d('<h1 id="commands" tabindex="-1">Commands <a class="header-anchor" href="#commands" aria-hidden="true">#</a></h1><p>This is a list of commands that the bot supports. The bot will also try respond to any command prefixed with <code>!</code>, but the intended way of using these commands is with a <code>/</code>.</p><h2 id="avaliable" tabindex="-1">Avaliable <a class="header-anchor" href="#avaliable" aria-hidden="true">#</a></h2><p>Lists all the available models that can be loaded for inference.</p><h2 id="clean-memory" tabindex="-1">Clean-memory <a class="header-anchor" href="#clean-memory" aria-hidden="true">#</a></h2><p>Manually clean the VRAM. For debugging purposes.</p><h2 id="dream" tabindex="-1">Dream <a class="header-anchor" href="#dream" aria-hidden="true">#</a></h2><p>Generate an image from a prompt.</p><ul><li><code>prompt</code> - The prompt to generate the image from.</li><li><code>model</code> - The model to use.</li><li><code>negative_prompt</code> - (Optional) The negative prompt to generate the image from. Default: <code>See source code - its too big for this page</code>.</li><li><code>guidance_scale</code> - (Optional) How closely the model should follow the prompt. Lower values will result in more creative images. Higher values will result in more predictable images. Default: <code>7</code>.</li><li><code>steps</code> - (Optional) How many steps to take in the inference process. Default: <code>30</code>.</li><li><code>resolution</code> - (Optional) The resolution of the generated image. Options: <code>512x512</code>,<code>1024x1024</code>,<code>512x912</code>,<code>912x512</code>,<code>1920x1080</code>,<code>1080x1920</code>,<code>1280x720</code>, <code>720x1280</code>,<code>768x768</code>. Default: <code>512x512</code>.</li><li><code>seed</code> - (Optional) The seed to use for the inference process. Default: <code>Random seed generated on runtime</code>.</li><li><code>scheduler</code> - (Optional) The scheduler to use for the inference process. Default: <code>13</code> (UniPCMultistep).</li><li><code>use_default_negative_prompt</code> - (Optional) Whether to use the default negative prompt. Default: <code>True</code>.</li><li><code>verbose</code> - (Optional) Whether to show generation table with all the information. Default: <code>False</code>.</li></ul><h2 id="gpus" tabindex="-1">GPUS <a class="header-anchor" href="#gpus" aria-hidden="true">#</a></h2><p>List all the GPUs available that the API can use.</p><h2 id="load" tabindex="-1">Load <a class="header-anchor" href="#load" aria-hidden="true">#</a></h2><p>Load a locally saved model.</p><ul><li><code>model</code> - The model to load.</li><li><code>device</code> - (Optional) The device to use for the inference process. Default: <code>cuda</code>.</li><li><code>backend</code> - (Optional) The backend to use for the inference process. Options: <code>PyTorch</code>,<code>TensorRT</code>. Default: <code>PyTorch</code>.</li></ul><h2 id="loaded" tabindex="-1">Loaded <a class="header-anchor" href="#loaded" aria-hidden="true">#</a></h2><p>List all the loaded models.</p><h2 id="reset-queue" tabindex="-1">Reset-queue <a class="header-anchor" href="#reset-queue" aria-hidden="true">#</a></h2><p>Clears the queue in case a job gets stuck. For debugging purposes.</p><h2 id="sync" tabindex="-1">Sync <a class="header-anchor" href="#sync" aria-hidden="true">#</a></h2><div class="info custom-block"><p class="custom-block-title">INFO</p><p>This command is for developers and debugging. You need to run this command only if you updated the command parameters and you want to sync them with Discord.</p></div><p>Sync all the commands with Discord. This is only needed the first time you start the bot and if you followed the docs properly, you already have this set up correctly.</p><h2 id="unload" tabindex="-1">Unload <a class="header-anchor" href="#unload" aria-hidden="true">#</a></h2><p>Unload a locally saved model.</p>',23),i=[t];function c(n,r,s,h,u,p){return o(),a("div",null,i)}const g=e(l,[["render",c]]);export{f as __pageData,g as default};
