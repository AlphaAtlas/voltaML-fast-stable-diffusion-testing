import{_ as e,c as t,o as i,a as o}from"./app.004c2493.js";const f=JSON.parse('{"title":"Optimization","description":"","frontmatter":{},"headers":[{"level":2,"title":"Optimization Levels","slug":"optimization-levels","link":"#optimization-levels","children":[]}],"relativePath":"experimental/optimization.md","lastUpdated":1680382375000}'),a={name:"experimental/optimization.md"},l=o('<h1 id="optimization" tabindex="-1">Optimization <a class="header-anchor" href="#optimization" aria-hidden="true">#</a></h1><p>Volta supports multiple optimization levels for PyTorch. Optimization levels can be set in multiple ways:</p><ol><li><code>-o [0,1,2,3,4]</code> / <code>--optimization [0,1,2,3,4]</code> flag in the command line when starting volta.</li><li><code>OPT_LEVEL</code> environment variable.</li><li>UI Settings page: <code>Settings &gt; API &gt; Optimization</code></li></ol><h2 id="optimization-levels" tabindex="-1">Optimization Levels <a class="header-anchor" href="#optimization-levels" aria-hidden="true">#</a></h2><p>Higher the number, the less VRAM it should consume - but with a performance hit.</p><ul><li><code>0</code>: Traced UNet - Takes about 15s to trace (happens every load)</li><li><code>1</code>: Default - No extra stuff applied</li><li><code>2</code>: Splits the step into smaller pieces (saves some VRAM for high resolution images) - UNet Attention Slicing</li><li><code>3</code>: Splitting into smaller pieces and offloading model to CPU when not needed (for multimodel setup) - Offloaded VAE &amp; UNet to CPU + UNet Slicing</li><li><code>4</code>: Offload unused componets to CPU (saves a lot of VRAM - <strong>recommended for 4GB cards</strong>) - Sequential Offload + UNet slicing</li></ul>',6),n=[l];function s(d,c,r,p,m,h){return i(),t("div",null,n)}const u=e(a,[["render",s]]);export{f as __pageData,u as default};
